{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T05:56:51.821772Z",
     "start_time": "2022-07-09T05:56:51.260293Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f068fe40b147ccacc8e5bd4418295f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='elev', options=(0, 15, 30), value=0), IntSlider(value=60, descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from mpl_toolkits import mplot3d\n",
    "import numpy as np\n",
    "\n",
    "w1 = np.arange(-10,10,0.05)\n",
    "w2 = np.arange(-10,10,0.05)\n",
    "w1, w2 = np.meshgrid(w1, w2)\n",
    "lossfn = (2 - w1 - w2)**2 + (4 - 3*w1 - w2)**2\n",
    "\n",
    "#定义一个绘制三维图像的函数\n",
    "#elev表示上下旋转的角度\n",
    "#azim表示平行旋转的角度\n",
    "\n",
    "def plot_3D(elev=45,azim=60,X=w1,y=w2):\n",
    "    fig, ax = plt.subplots(1, 1,constrained_layout=True, figsize=(8, 8))\n",
    "    ax = plt.subplot(projection=\"3d\")\n",
    "    ax.plot_surface(w1, w2, lossfn, cmap='rainbow',alpha=0.7)\n",
    "    ax.view_init(elev=elev,azim=azim)\n",
    "    #ax.xticks([-10,-5,0,5,10])\n",
    "    ax.set_xlabel(\"w1\",fontsize=20)\n",
    "    ax.set_ylabel(\"w2\",fontsize=20)\n",
    "    ax.set_zlabel(\"lossfn\",fontsize=20)\n",
    "    plt.show()\n",
    "\n",
    "from ipywidgets import interact,fixed\n",
    "interact(plot_3D,elev=[0,15,30],azip=(-180,180),X=fixed(w1),y=fixed(w2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在梯度下降的最初，我们需要先找出坐标点对应的梯度向量。梯度向量是各个自变量求偏导后的表达式\n",
    "再带入坐标点计算出来的，在这一步骤中，最大的难点在于如何获得梯度向量的表达式——也就是损失\n",
    "函数对各个自变量求偏导后的表达式。在单层神经网络，例如逻辑回归（二分类单层神经网络）中，我\n",
    "们有如下计算："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch 反向传播"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:11:02.730271Z",
     "start_time": "2022-07-09T06:11:01.829699Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-2.5379),)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.tensor(1,requires_grad=True, dtype=torch.float32)\n",
    "z = x**2\n",
    "y = torch.tensor(2,requires_grad=False, dtype=torch.float32)\n",
    "sigma = torch.sigmoid(z) \n",
    "loss = -(y*torch.log(sigma) + (1-y)*torch.log(1-sigma))\n",
    "torch.autograd.grad(loss,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:18:06.949211Z",
     "start_time": "2022-07-09T06:18:06.938333Z"
    }
   },
   "outputs": [],
   "source": [
    "# 多个数量进行反向传播\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import CrossEntropyLoss as CEL\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:18:07.265560Z",
     "start_time": "2022-07-09T06:18:07.258774Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ = X.shape[1]\n",
    "output_ = len(y.unique())\n",
    "\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=40,out_features=2):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_features,13,bias=False)\n",
    "        self.linear2 = nn.Linear(13,8,bias=False)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        zhat = self.output(sigma2)\n",
    "        return zhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:18:08.273104Z",
     "start_time": "2022-07-09T06:18:08.257509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.1559, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)\n",
    "zhat = net.forward(X)\n",
    "criterion = CEL()\n",
    "loss = criterion(zhat, y.long())\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:18:09.328581Z",
     "start_time": "2022-07-09T06:18:09.326993Z"
    }
   },
   "outputs": [],
   "source": [
    "net.linear1.weight.grad #还没有梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:18:09.605152Z",
     "start_time": "2022-07-09T06:18:09.597796Z"
    }
   },
   "outputs": [],
   "source": [
    "loss.backward(retain_graph=True) # 保存计算图可以多次反向传播，不保存只传播一次"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:18:09.974523Z",
     "start_time": "2022-07-09T06:18:09.968054Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-3.0294e-04, -7.4869e-05, -3.6707e-04, -3.8675e-05, -1.3070e-04,\n",
       "         -5.8467e-05, -3.3313e-04, -2.5863e-04, -9.4271e-05, -4.2617e-05,\n",
       "         -7.9180e-05, -1.5179e-04, -9.2079e-05, -3.2513e-04, -1.0894e-04,\n",
       "         -6.5035e-05, -1.3006e-04, -4.4115e-06, -9.6739e-05, -8.5471e-05],\n",
       "        [ 1.0099e-02, -9.9189e-04,  1.2005e-02,  1.0410e-03,  5.1961e-03,\n",
       "          3.5567e-03,  6.0618e-03,  3.9976e-03,  1.4981e-02,  9.0948e-03,\n",
       "          6.0929e-03,  7.5188e-03,  1.3888e-02,  1.1927e-03,  8.9806e-03,\n",
       "          9.8215e-03,  1.7637e-02,  1.0377e-02,  1.6778e-03,  7.8358e-04],\n",
       "        [-1.0467e-02,  7.9738e-03,  3.0350e-03,  7.4985e-03,  4.3230e-03,\n",
       "          9.8742e-04,  9.2578e-03,  6.3660e-03, -5.8071e-03,  1.1588e-03,\n",
       "         -2.6623e-03,  6.3559e-03, -2.9338e-03, -4.4924e-03, -5.0406e-03,\n",
       "          8.4390e-03, -1.0344e-02, -8.5044e-03,  2.1374e-03, -1.2447e-03],\n",
       "        [-1.3464e-02, -1.0530e-02, -8.3316e-03, -1.5648e-02, -1.2376e-02,\n",
       "         -1.6419e-02, -9.7809e-03, -1.6176e-02, -7.5129e-03, -1.6220e-02,\n",
       "         -1.0425e-02, -7.7203e-03, -2.6543e-03, -1.4025e-02, -9.4273e-03,\n",
       "         -1.4208e-02, -9.8492e-03, -1.2527e-02, -1.9432e-02, -1.1801e-02],\n",
       "        [-2.4001e-02, -2.2049e-02, -1.9075e-02, -2.4805e-02, -1.4982e-02,\n",
       "         -1.4487e-02, -1.7842e-02, -2.5486e-02, -1.6000e-02, -3.2270e-02,\n",
       "         -6.3227e-03, -2.9843e-02, -4.5610e-03, -1.3760e-02, -1.5680e-02,\n",
       "         -2.4157e-02, -2.1648e-02, -1.4690e-02, -2.2686e-02, -2.0136e-02],\n",
       "        [-4.9099e-04,  1.2938e-03, -3.2794e-04, -5.8756e-04, -1.0273e-04,\n",
       "          1.4246e-03, -3.4932e-04,  9.8298e-04, -2.5764e-04, -1.4621e-04,\n",
       "         -4.4740e-04, -2.5354e-04,  1.9017e-04, -8.4186e-04,  2.5199e-04,\n",
       "          2.6533e-04,  2.6516e-04,  1.0733e-03,  1.0434e-03, -2.7481e-04],\n",
       "        [ 1.8667e-02,  2.0105e-02,  1.4331e-02,  1.7148e-02,  7.1022e-03,\n",
       "          2.9474e-02,  1.9639e-02,  1.6606e-02, -3.9072e-03,  5.3112e-02,\n",
       "          2.5341e-03,  3.9633e-02,  6.0932e-03,  2.2678e-02,  3.3614e-03,\n",
       "          3.0149e-02,  1.6826e-02,  1.6251e-02,  3.4115e-02,  2.9516e-02],\n",
       "        [ 2.5575e-02,  5.2925e-03,  6.6924e-03,  4.6901e-03,  8.3948e-03,\n",
       "          5.2274e-03,  3.1384e-03,  6.9073e-03,  2.7986e-02,  4.0137e-03,\n",
       "          1.0056e-02,  9.9030e-03,  1.4389e-02,  1.5045e-02,  1.7513e-02,\n",
       "          5.1190e-03,  2.0432e-02,  1.7921e-02,  1.2467e-02,  1.0878e-03],\n",
       "        [-2.6368e-02, -2.5858e-02, -2.9701e-02, -2.3503e-02, -2.4305e-02,\n",
       "         -3.3645e-02, -1.9366e-02, -2.3217e-02, -1.2061e-02, -3.7455e-02,\n",
       "         -1.4216e-02, -3.7164e-02, -1.6988e-02, -2.9700e-02, -2.0395e-02,\n",
       "         -3.6110e-02, -2.7453e-02, -1.9892e-02, -3.7484e-02, -4.0446e-02],\n",
       "        [ 3.0670e-03,  2.3949e-03,  5.5598e-03, -5.5754e-03, -5.0398e-03,\n",
       "         -6.5433e-03,  7.7753e-04, -7.7903e-03, -2.6769e-03, -5.9715e-04,\n",
       "         -1.7679e-03, -2.9360e-03,  7.9956e-04, -1.0231e-03, -1.6204e-03,\n",
       "          1.7842e-03,  8.9686e-04, -2.2975e-03,  2.1827e-03,  1.3285e-03],\n",
       "        [ 5.1343e-03,  1.7690e-03,  2.3953e-03,  3.4648e-03,  1.6590e-03,\n",
       "          5.5399e-04,  5.7126e-05,  9.1988e-04,  1.9024e-03,  3.2499e-03,\n",
       "          2.7058e-03,  1.0736e-03,  1.9884e-03,  2.1006e-03,  1.6670e-03,\n",
       "          1.1112e-03,  2.9293e-03,  4.1532e-03,  2.9811e-03,  2.6034e-03],\n",
       "        [-1.0980e-02, -1.1791e-02, -2.0945e-03, -5.3406e-03, -8.9154e-03,\n",
       "         -1.1582e-02, -5.7907e-03, -1.3181e-02, -1.8497e-02, -1.3750e-02,\n",
       "         -5.2399e-03, -7.5829e-03, -1.1019e-02, -1.4631e-02, -9.4829e-03,\n",
       "         -7.1365e-03, -1.3495e-02, -1.0724e-02, -1.0035e-02, -4.0535e-03],\n",
       "        [ 2.5406e-04,  3.8109e-04,  6.1133e-05,  5.1588e-04,  1.0562e-03,\n",
       "          9.5466e-04,  6.7450e-04,  1.0621e-03,  1.1541e-04,  1.8141e-03,\n",
       "          5.5162e-04,  6.6329e-04,  2.4456e-04,  1.9338e-04,  1.0474e-03,\n",
       "          1.9811e-04,  4.7523e-04,  1.6118e-03,  5.2851e-04,  2.4157e-04]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.grad # 查看对应的梯度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "w(t+1) = w(t) - 步长 * grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:23:21.621082Z",
     "start_time": "2022-07-09T06:23:21.616678Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
       "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
       "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
       "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
       "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
       "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
       "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
       "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
       "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
       "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
       "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
       "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
       "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
       "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
       "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
       "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
       "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
       "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
       "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
       "          1.1362e-01,  1.4100e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
       "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
       "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
       "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
       "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
       "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
       "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
       "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
       "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
       "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
       "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
       "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
       "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
       "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
       "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
       "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
       "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
       "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
       "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
       "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
       "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
       "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
       "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
       "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
       "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
       "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
       "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
       "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
       "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
       "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
       "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
       "         -2.9401e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
       "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.linear1.weight.data #返回相应的权重值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:29:08.995581Z",
     "start_time": "2022-07-09T06:29:08.993461Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 10 #learning_rate, 0.001,0.01,0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:29:18.551792Z",
     "start_time": "2022-07-09T06:29:18.542329Z"
    }
   },
   "outputs": [],
   "source": [
    "w = net.linear1.weight.data #现有的权重，w(t)\n",
    "dw = net.linear1.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T06:29:34.463148Z",
     "start_time": "2022-07-09T06:29:34.457517Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4868e-01, -1.3160e-01,  2.2749e-01, -1.7608e-01, -6.2990e-02,\n",
       "         -1.5176e-01,  1.8578e-01,  9.4230e-02, -1.0776e-01, -1.7123e-01,\n",
       "         -1.2630e-01, -3.7066e-02, -1.1045e-01,  1.7595e-01, -8.9725e-02,\n",
       "         -1.4368e-01, -6.3780e-02, -2.1819e-01, -1.0472e-01, -1.1857e-01],\n",
       "        [-3.5582e-01,  2.2153e-01, -4.5607e-01, -1.7196e-01, -1.1579e-01,\n",
       "         -2.3747e-01, -3.4831e-01, -2.0276e-01, -7.1593e-01, -3.3921e-01,\n",
       "         -6.2197e-02, -2.7025e-01, -4.2048e-01, -2.4196e-01, -5.3514e-01,\n",
       "         -4.2261e-01, -7.0528e-01, -2.7552e-01, -2.6377e-01,  6.1950e-02],\n",
       "        [ 2.2677e-01, -2.8288e-01,  2.6378e-02, -2.6910e-01, -1.0153e-01,\n",
       "          1.0267e-01, -1.4909e-01, -3.9496e-01,  3.0554e-01,  1.3774e-01,\n",
       "          2.3365e-01, -4.5676e-01, -3.7733e-02, -3.9295e-02,  3.0061e-01,\n",
       "         -1.1633e-01,  1.9717e-01,  5.1898e-01, -2.9471e-01,  2.2513e-02],\n",
       "        [ 7.2001e-01,  3.8603e-01,  3.5807e-01,  7.8890e-01,  3.0748e-01,\n",
       "          7.1337e-01,  2.8213e-01,  8.5227e-01,  1.0673e-01,  6.6571e-01,\n",
       "          5.5667e-01,  1.7744e-01, -2.5833e-02,  6.3757e-01,  2.0151e-01,\n",
       "          6.9929e-01,  4.2115e-01,  2.8098e-01,  8.5416e-01,  2.8473e-01],\n",
       "        [ 9.8744e-01,  1.0190e+00,  7.2432e-01,  1.0757e+00,  5.8366e-01,\n",
       "          4.1167e-01,  4.9940e-01,  1.2041e+00,  7.2391e-01,  1.3507e+00,\n",
       "          4.7528e-02,  1.1659e+00,  2.2988e-01,  3.5258e-01,  4.4877e-01,\n",
       "          1.0799e+00,  1.0069e+00,  4.4965e-01,  1.0245e+00,  7.7133e-01],\n",
       "        [ 5.8027e-02, -2.2444e-01, -8.9237e-02, -1.0284e-01, -1.1473e-01,\n",
       "         -1.9161e-01, -1.6213e-01, -2.7764e-03, -1.6803e-01, -1.5886e-01,\n",
       "          2.2624e-01,  1.9414e-01, -9.6329e-02, -4.1704e-02,  1.6869e-01,\n",
       "         -6.7872e-02, -3.5129e-02, -5.4755e-02, -2.2369e-01,  2.0912e-01],\n",
       "        [-7.6871e-01, -5.8574e-01, -3.8915e-01, -5.8874e-01, -2.8915e-01,\n",
       "         -1.1814e+00, -7.8044e-01, -8.8158e-01,  1.0291e-01, -2.2279e+00,\n",
       "         -1.1467e-01, -1.5580e+00, -4.1896e-01, -7.3717e-01,  4.8130e-02,\n",
       "         -1.0669e+00, -5.7263e-01, -6.1465e-01, -1.5257e+00, -1.0906e+00],\n",
       "        [-9.4378e-01,  4.4351e-03, -4.7856e-01,  6.4662e-03, -1.6020e-01,\n",
       "         -1.6763e-01, -5.1055e-02, -2.4956e-01, -1.1373e+00, -1.1551e-01,\n",
       "         -2.7277e-01, -3.7064e-01, -5.9587e-01, -6.0918e-01, -8.7274e-01,\n",
       "         -3.1181e-01, -6.3525e-01, -7.0367e-01, -4.7523e-01, -2.3918e-01],\n",
       "        [ 1.2181e+00,  1.0423e+00,  1.1582e+00,  7.2128e-01,  1.1069e+00,\n",
       "          1.3169e+00,  5.8705e-01,  9.3759e-01,  6.9183e-01,  1.5891e+00,\n",
       "          4.8565e-01,  1.4775e+00,  7.7997e-01,  1.1711e+00,  6.7843e-01,\n",
       "          1.6124e+00,  9.0472e-01,  7.6087e-01,  1.5999e+00,  1.6401e+00],\n",
       "        [ 2.3433e-02,  4.8345e-02, -2.4549e-01,  3.0496e-01,  2.0757e-01,\n",
       "          3.2941e-01,  1.2144e-01,  4.7904e-01, -6.1882e-02,  1.3959e-01,\n",
       "         -1.1466e-01,  1.4075e-01, -1.9345e-01,  1.4322e-01, -1.0832e-01,\n",
       "         -2.6043e-01, -2.3874e-01,  7.0690e-02, -1.0911e-01, -9.1060e-02],\n",
       "        [-1.1621e-02, -1.6838e-02, -2.4482e-01,  2.8494e-02, -2.3288e-01,\n",
       "          4.0204e-02, -4.3859e-02, -2.4244e-01, -2.1259e-01, -3.3600e-01,\n",
       "         -2.9855e-01, -1.3189e-01, -1.5760e-01,  7.9205e-02, -1.9843e-01,\n",
       "          1.4190e-02,  9.3994e-02,  9.4429e-04, -1.7874e-01, -3.1387e-01],\n",
       "        [ 4.1355e-01,  4.6084e-01,  5.0731e-02,  2.5070e-01,  2.4852e-01,\n",
       "          6.6970e-01,  3.5559e-01,  3.1200e-01,  8.6159e-01,  4.0679e-01,\n",
       "          3.2294e-01,  3.5025e-01,  5.2533e-01,  7.9053e-01,  2.6099e-01,\n",
       "          4.7832e-01,  5.1142e-01,  4.3612e-01,  1.9085e-01,  2.7018e-01],\n",
       "        [-1.3274e-01, -8.3568e-02, -2.2174e-01, -1.7003e-01,  1.5001e-01,\n",
       "         -1.0111e-01, -1.0336e-01,  1.7707e-01, -5.0455e-02, -6.2762e-02,\n",
       "         -2.5005e-02, -1.2177e-01, -8.9557e-02, -1.9482e-01,  1.3639e-01,\n",
       "         -1.8344e-01, -1.2229e-01, -8.4169e-02, -1.9563e-01,  1.0745e-02]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w -= lr*dw\n",
    "w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "普通梯度下降就是在重复正向传播、计算梯度、更新权重的过程，但这个过程往往非常漫长。如大家所\n",
    "见，步长设置为0.001时，我们看不到w任何的变化，只有当步长设置得非常巨大，我们才能够看到一些\n",
    "改变，但在之前的课程中我们说过，巨大的步长可能会让我们跳过真正的最小值，所以我们无法将步长\n",
    "设置得很大，无论如何，梯度下降都是一个缓慢的过程。在这个基础上，我们提出了加速迭代的数个方\n",
    "法，其中一个很关键的方法，就是使用动量Momentum。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之前我们说过，在梯度下降过程中，起始点是一个“盲人”，它看不到也听不到全局，所以我们每移动一\n",
    "次都要重新计算方向与距离，并且每次只能走一小步。但不只限于此，起始点不仅看不到前面的路，也\n",
    "无法从过去走的路中学习。\n",
    "想象一下，我们被蒙上眼睛，由另一个人喊口号来给与我们方向让我们移动，假设喊口号的人一直喊：”\n",
    "向前，向前，向前。“因为我们看不见，在最初的三四次，我们可能都只会向前走一小步，但如果他一直\n",
    "让我们向前，我们就会失去耐心，转而向前走一大步，因为我们可以预测：前面很长一段路大概都是需\n",
    "要向前的。对梯度下降来说，也是同样的道理——如果在很长一段时间内，起始点一直向相似的方向移\n",
    "动，那按照步长一小步一小步地磨着向前是没有意义的，既浪费计算资源又浪费时间，此时就应该大但\n",
    "地照着这个方向走一大步。相对的，如果我们很长时间都走向同一个方向，突然让我们转向，那我们转\n",
    "向的第一步就应该非常谨慎，走一小步。\n",
    "不难发现，真正高效的方法是：在历史方向与现有方向相同的情况下，迈出大步子，在历史方向与现有\n",
    "方向相反的情况下，迈出小步子。那要怎么才能让起始点了解过去的方向呢？我们让上一步的梯度向量\n",
    "与现在这一点的梯度向量以加权的方式求和，求解出受到上一步大小和方向影响的真实下降方向，再让\n",
    "坐标点向真实下降方向移动。在坐标轴上，可以表示为"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T07:02:55.226103Z",
     "start_time": "2022-07-09T07:02:55.221527Z"
    }
   },
   "outputs": [],
   "source": [
    "#恢复小步长\n",
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "dw = net.linear1.weight.grad\n",
    "w = net.linear1.weight.data\n",
    "v = torch.zeros(dw.shape[0],dw.shape[1])\n",
    "#v要能够跟dw相减，因此必须和dw保持相同的结构，初始v为0，但后续v会越来越大"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-09T07:02:55.243587Z",
     "start_time": "2022-07-09T07:02:55.241319Z"
    }
   },
   "outputs": [],
   "source": [
    "v = gamma * v - lr * dw # 保持和梯度减同方向了\n",
    "w += v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 整体流程 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:00.538090Z",
     "start_time": "2022-07-15T13:31:18.185780Z"
    }
   },
   "outputs": [],
   "source": [
    "##导入库\n",
    "#确定数据、超参数的确定（lr，gamma）\n",
    "#定义伸进网络的架构类Model，类Model需要输入的参数\n",
    "##实例化神经网络的类 - 让神经网络准备好进行正向传播\n",
    "#定义损失函数\n",
    "#定义优化算法\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:01.793657Z",
     "start_time": "2022-07-15T13:34:00.541260Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(420)\n",
    "X = torch.rand((500,20),dtype=torch.float32) * 100\n",
    "y = torch.randint(low=0,high=3,size=(500,),dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:01.804611Z",
     "start_time": "2022-07-15T13:34:01.796305Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "gamma = 0.9\n",
    "class Model(nn.Module):\n",
    "    def __init__(self,in_features=10,out_features=2):\n",
    "        super(Model,self).__init__() #super(请查找这个类的父类，请使用找到的父类替换现在的类)\n",
    "        self.linear1 = nn.Linear(in_features,13,bias=True) #输入层不用写，这里是隐藏层的第一层\n",
    "        self.linear2 = nn.Linear(13,8,bias=True)\n",
    "        self.output = nn.Linear(8,out_features,bias=True)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "        sigma2 = torch.sigmoid(self.linear2(sigma1))\n",
    "        zhat = self.output(sigma2)\n",
    "        return zhat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:02.025352Z",
     "start_time": "2022-07-15T13:34:01.808324Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ = X.shape[1] #特征的数目\n",
    "output_ = len(y.unique()) #分类的数目"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:02.143942Z",
     "start_time": "2022-07-15T13:34:02.027333Z"
    }
   },
   "outputs": [],
   "source": [
    "#实例化神经网络类\n",
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:02.813623Z",
     "start_time": "2022-07-15T13:34:02.146132Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 1.3656e-01, -1.3459e-01,  2.1281e-01, -1.7763e-01, -6.8218e-02,\n",
      "         -1.5410e-01,  1.7245e-01,  8.3885e-02, -1.1153e-01, -1.7294e-01,\n",
      "         -1.2947e-01, -4.3138e-02, -1.1413e-01,  1.6295e-01, -9.4082e-02,\n",
      "         -1.4629e-01, -6.8982e-02, -2.1836e-01, -1.0859e-01, -1.2199e-01],\n",
      "        [ 4.8127e-02,  1.8186e-01,  2.4149e-02, -1.3032e-01,  9.2056e-02,\n",
      "         -9.5202e-02, -1.0584e-01, -4.2852e-02, -1.1669e-01,  2.4581e-02,\n",
      "          1.8152e-01,  3.0500e-02,  1.3506e-01, -1.9425e-01, -1.7591e-01,\n",
      "         -2.9751e-02,  2.0485e-04,  1.3957e-01, -1.9666e-01,  9.3293e-02],\n",
      "        [-1.9192e-01,  3.6070e-02,  1.4778e-01,  3.0845e-02,  7.1393e-02,\n",
      "          1.4217e-01,  2.2122e-01, -1.4032e-01,  7.3255e-02,  1.8409e-01,\n",
      "          1.2716e-01, -2.0253e-01, -1.5509e-01, -2.1899e-01,  9.8980e-02,\n",
      "          2.2123e-01, -2.1659e-01,  1.7880e-01, -2.0922e-01, -2.7275e-02],\n",
      "        [ 1.8144e-01, -3.5166e-02,  2.4801e-02,  1.6299e-01, -1.8755e-01,\n",
      "          5.6587e-02, -1.0911e-01,  2.0523e-01, -1.9378e-01,  1.6899e-02,\n",
      "          1.3966e-01, -1.3137e-01, -1.3201e-01,  7.6554e-02, -1.7558e-01,\n",
      "          1.3096e-01,  2.7182e-02, -2.2010e-01,  7.6883e-02, -1.8731e-01],\n",
      "        [ 2.7419e-02,  1.3699e-01, -3.8687e-02,  8.3463e-02, -1.5634e-02,\n",
      "         -1.6781e-01, -2.1426e-01,  1.8463e-01,  8.3891e-02,  5.9950e-02,\n",
      "         -2.0538e-01, -2.7832e-02,  4.7442e-02, -1.9782e-01, -1.7842e-01,\n",
      "          1.1362e-01,  1.4100e-01, -1.3794e-01,  1.1704e-01, -3.4108e-02],\n",
      "        [ 3.8388e-02, -1.7268e-01, -1.0235e-01, -1.2634e-01, -1.1883e-01,\n",
      "         -1.3463e-01, -1.7610e-01,  3.6543e-02, -1.7834e-01, -1.6471e-01,\n",
      "          2.0834e-01,  1.8400e-01, -8.8723e-02, -7.5378e-02,  1.7877e-01,\n",
      "         -5.7259e-02, -2.4522e-02, -1.1822e-02, -1.8196e-01,  1.9812e-01],\n",
      "        [-2.2011e-02,  2.1847e-01,  1.8410e-01,  9.7177e-02, -5.0634e-03,\n",
      "         -2.4731e-03,  5.1408e-03, -2.1733e-01, -5.3375e-02, -1.0346e-01,\n",
      "         -1.3303e-02,  2.7354e-02, -1.7523e-01,  1.6994e-01,  1.8259e-01,\n",
      "          1.3907e-01,  1.0041e-01,  3.5377e-02, -1.6114e-01,  9.0056e-02],\n",
      "        [ 7.9232e-02,  2.1614e-01, -2.1087e-01,  1.9407e-01,  1.7559e-01,\n",
      "          4.1470e-02,  7.4482e-02,  2.6737e-02, -1.7872e-02,  4.5040e-02,\n",
      "          1.2947e-01,  2.5483e-02, -2.0320e-02, -7.3942e-03, -1.7221e-01,\n",
      "         -1.0705e-01,  1.8203e-01,  1.3179e-02,  2.3468e-02, -1.9567e-01],\n",
      "        [ 1.6338e-01,  8.0209e-03, -2.9885e-02, -2.1884e-01,  1.3471e-01,\n",
      "         -2.8901e-02, -1.8757e-01,  8.9256e-03,  2.0940e-01,  9.0927e-02,\n",
      "         -8.2969e-02, -9.0893e-03,  1.0047e-01, -1.6897e-02, -1.3736e-01,\n",
      "          1.6801e-01, -1.9342e-01, -3.4822e-02,  1.0057e-01,  2.2273e-02],\n",
      "        [ 1.4611e-01,  1.4414e-01, -2.3093e-02,  8.1946e-02,  5.9792e-03,\n",
      "          6.7672e-02,  1.5254e-01,  1.6742e-01, -1.6896e-01,  1.1571e-01,\n",
      "         -1.8538e-01,  2.3316e-02, -1.6147e-01,  1.0230e-01, -1.7314e-01,\n",
      "         -1.8906e-01, -2.0286e-01, -2.1210e-02, -2.1799e-02, -3.7921e-02],\n",
      "        [ 1.9375e-01,  5.3921e-02, -1.4900e-01,  1.6709e-01, -1.6652e-01,\n",
      "          6.2363e-02, -4.1574e-02, -2.0565e-01, -1.3649e-01, -2.0600e-01,\n",
      "         -1.9032e-01, -8.8942e-02, -7.8061e-02,  1.6323e-01, -1.3174e-01,\n",
      "          5.8638e-02,  2.1117e-01,  1.6707e-01, -5.9492e-02, -2.0973e-01],\n",
      "        [-2.5644e-02, -1.0818e-02, -3.3051e-02,  3.7071e-02, -1.0809e-01,\n",
      "          2.0642e-01,  1.2396e-01, -2.1523e-01,  1.2172e-01, -1.4323e-01,\n",
      "          1.1334e-01,  4.6931e-02,  8.4553e-02,  2.0530e-01, -1.1833e-01,\n",
      "          1.9287e-01, -2.8398e-02,  7.1443e-03, -2.1055e-01,  1.0805e-01],\n",
      "        [-1.2258e-01, -6.8325e-02, -2.1929e-01, -1.4939e-01,  1.9226e-01,\n",
      "         -6.2922e-02, -7.6377e-02,  2.1955e-01, -4.5838e-02,  9.8011e-03,\n",
      "         -2.9401e-03, -9.5241e-02, -7.9775e-02, -1.8708e-01,  1.7828e-01,\n",
      "         -1.7552e-01, -1.0328e-01, -1.9697e-02, -1.7449e-01,  2.0408e-02]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.3508e-01,  1.5439e-01, -1.9350e-01, -6.8777e-02,  1.3787e-01,\n",
      "        -1.8474e-01,  1.2763e-01,  1.8031e-01,  9.5152e-02, -1.2660e-01,\n",
      "         1.4317e-01, -1.4945e-01,  3.4253e-05], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0854,  0.0825,  0.1020, -0.0941,  0.2054,  0.2645, -0.2198, -0.0169,\n",
      "          0.0017, -0.2714, -0.1154,  0.0410, -0.0668],\n",
      "        [-0.2668,  0.1752, -0.2743,  0.1611, -0.1190,  0.0476,  0.0036,  0.2185,\n",
      "         -0.1021,  0.2397,  0.1055, -0.0704, -0.1420],\n",
      "        [ 0.2249, -0.2563, -0.2121, -0.0678,  0.1129,  0.0035,  0.0988,  0.2494,\n",
      "          0.1891, -0.0448,  0.1583,  0.0126,  0.2220],\n",
      "        [-0.2095, -0.1938, -0.0562, -0.2183, -0.2483,  0.2078,  0.2142,  0.0754,\n",
      "         -0.2532,  0.1142,  0.0657, -0.0808,  0.2725],\n",
      "        [ 0.2063,  0.0870, -0.2641,  0.2648,  0.1443, -0.2759,  0.0101,  0.1611,\n",
      "          0.2489, -0.1175,  0.0537, -0.0365,  0.2095],\n",
      "        [ 0.2333, -0.0148, -0.2440,  0.0268,  0.1815,  0.2528, -0.2730,  0.2145,\n",
      "          0.0205, -0.2279,  0.0727, -0.2309, -0.1754],\n",
      "        [-0.1644, -0.0508,  0.0548,  0.0702, -0.1867, -0.0818,  0.2041, -0.0269,\n",
      "         -0.1098, -0.0464,  0.1511,  0.0050, -0.1364],\n",
      "        [ 0.2180, -0.0104,  0.1469, -0.0562, -0.2288, -0.0920,  0.1706, -0.1874,\n",
      "         -0.1059, -0.0818, -0.2628, -0.2723,  0.1970]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0900, -0.0597,  0.0268, -0.0173,  0.0065,  0.0228, -0.1408,  0.1188],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.1259,  0.1116, -0.0097, -0.1100,  0.0427,  0.3335, -0.2140, -0.2908],\n",
      "        [-0.0166,  0.0617, -0.2413,  0.0719, -0.0847, -0.0331, -0.1862,  0.1859],\n",
      "        [-0.1704,  0.1227,  0.3419,  0.0164, -0.2700, -0.0598, -0.2827, -0.3440]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0156, -0.0730, -0.2637], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for x in net.parameters():\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:02.819349Z",
     "start_time": "2022-07-15T13:34:02.815581Z"
    }
   },
   "outputs": [],
   "source": [
    "#定义损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "opt = optim.SGD(net.parameters()#需要进行迭代的权重\n",
    "                ,lr = lr\n",
    "                ,momentum = gamma\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:34:03.415323Z",
     "start_time": "2022-07-15T13:34:02.821309Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.1057, grad_fn=<NllLossBackward0>)\n",
      "tensor([ 0.1365, -0.1346,  0.2128, -0.1776, -0.0682, -0.1541,  0.1724,  0.0839,\n",
      "        -0.1115, -0.1729])\n"
     ]
    }
   ],
   "source": [
    "zhat = net.forward(X) #最后一个线性层的输出结果，向前传播\n",
    "loss = criterion(zhat, y.reshape(500).long()) #计算损失函数\n",
    "loss.backward()\n",
    "opt.step() #步子，走一步，更新权重w，更新动量v\n",
    "opt.zero_grad()\n",
    "\n",
    "print(loss)\n",
    "print(net.linear1.weight.data[0][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epochs in range(epoch):\n",
    "    for batch in range(batch):\n",
    "        zhat = net.forward(X) #最后一个线性层的输出结果，向前传播\n",
    "        loss = criterion(zhat, y.reshape(500).long()) #计算损失函数\n",
    "        loss.backward()\n",
    "        opt.step() #步子，走一步，更新权重w，更新动量v\n",
    "        opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## batch\n",
    "\n",
    "小批量，每一次变化更大，更有可能全局最优。\n",
    "缺点：需要迭代的次数可能更多。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据TensorDataset，DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:51:50.826484Z",
     "start_time": "2022-07-15T13:51:50.821683Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:51:51.105780Z",
     "start_time": "2022-07-15T13:51:51.101062Z"
    }
   },
   "outputs": [],
   "source": [
    "# 500代表样本个数\n",
    "a = torch.randn(500,2,3) #三维数据 - 二维表格\n",
    "b = torch.randn(500,3,4,5) #四维数据 - 图像\n",
    "c = torch.randn(500,1) #二维数据 - 标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:51:52.559594Z",
     "start_time": "2022-07-15T13:51:51.348088Z"
    }
   },
   "outputs": [],
   "source": [
    "data = TensorDataset(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T13:51:59.648154Z",
     "start_time": "2022-07-15T13:51:59.641676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[[ 0.3641,  1.1461,  1.3315, -0.6803, -0.1573],\n",
      "         [-0.3813,  0.0569,  1.4741, -0.2237,  0.4374],\n",
      "         [ 0.4338,  0.7315, -0.2749,  0.0160, -0.2451],\n",
      "         [-0.5867, -0.5889,  1.8905, -0.7718, -1.7899]],\n",
      "\n",
      "        [[-0.4048,  0.7898,  0.3773,  0.7166,  0.0490],\n",
      "         [-0.9121, -0.0489, -0.8179, -1.8548, -0.3418],\n",
      "         [ 0.0873,  0.3071, -0.9272,  1.4546, -0.8360],\n",
      "         [ 1.2235,  1.2197, -0.5222,  0.2297, -0.8180]],\n",
      "\n",
      "        [[ 0.4578, -2.0396, -0.1589, -0.3033, -0.6102],\n",
      "         [ 1.1299,  0.8919, -0.5627,  0.4364, -0.2321],\n",
      "         [ 0.1634,  1.4667, -0.7651, -0.6503,  0.0228],\n",
      "         [ 0.8123,  0.9057,  1.3573, -0.3826,  0.2580]]]), tensor([-0.4762]))\n"
     ]
    }
   ],
   "source": [
    "for x in TensorDataset(b,c):#generator\n",
    "    print(x) # b对应4,5\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader用来切割小批量\n",
    "DataLoader(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = DataLoader(data\n",
    "          , batch_size = 24\n",
    "          , shuffle = True #划分小批量之前请随机打乱我们的数据\n",
    "          , drop_last = True #你要舍弃最后一个batch吗？\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset) #一共有多少个batch\n",
    "len(dataset.dataset) #展示里面全部的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dataset[0] #单个样本\n",
    "dataset.batch_size #查看现有的batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在MINST-FASHION上实现神经网络的学习流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T14:18:29.390670Z",
     "start_time": "2022-07-15T14:18:27.926097Z"
    }
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms #处理数据模块\n",
    "#dataloader、TensorDataset - 对数据的结构、归纳方式进行变换\n",
    "#torchvision.transforms - 对数据集的数字本身进行修改"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T14:21:18.688672Z",
     "start_time": "2022-07-15T14:21:18.645586Z"
    }
   },
   "outputs": [],
   "source": [
    "mnist = torchvision.datasets.FashionMNIST(root = \"./\" #你的计算机上的某个目录\n",
    "                                          ,download = True\n",
    "                                          , train = True\n",
    "                                          , transform = transforms.ToTensor()\n",
    "                                         ) #实例化数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T14:21:43.897656Z",
     "start_time": "2022-07-15T14:21:43.887138Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset FashionMNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist #对于数据的一个说明"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T14:22:07.753242Z",
     "start_time": "2022-07-15T14:22:07.748400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.data.shape #特征张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T14:23:24.791371Z",
     "start_time": "2022-07-15T14:23:24.785869Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.targets.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T14:23:39.238203Z",
     "start_time": "2022-07-15T14:23:39.233265Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-15T14:24:01.461851Z",
     "start_time": "2022-07-15T14:24:00.071212Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "plt.imshow(mnist[0][0].view(28,28).numpy()); #imageshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T01:58:40.350671Z",
     "start_time": "2022-07-16T01:58:40.298904Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms \n",
    "\n",
    "#确定数据、确定超参数\n",
    "\n",
    "lr = 0.15\n",
    "gamma = 0\n",
    "epochs = 3\n",
    "bs = 128\n",
    "\n",
    "mnist = torchvision.datasets.FashionMNIST(root = \"./\" #你的计算机上的某个目录\n",
    "                                          ,download = False\n",
    "                                          , train = True\n",
    "                                          , transform = transforms.ToTensor()\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T01:58:40.869625Z",
     "start_time": "2022-07-16T01:58:40.353230Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 28, 28])\n",
      "torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "batchdata = DataLoader(mnist\n",
    "                       ,batch_size = bs\n",
    "                       ,shuffle = True)\n",
    "for x,y in batchdata:\n",
    "    print(x.shape)\n",
    "    print(y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T01:58:40.899400Z",
     "start_time": "2022-07-16T01:58:40.872225Z"
    }
   },
   "outputs": [],
   "source": [
    "input_ = mnist.data[0].numel() #28*28\n",
    "output_ = len(mnist.targets.unique()) # 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T02:00:03.337426Z",
     "start_time": "2022-07-16T02:00:03.329707Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, in_features=10, out_features=2):\n",
    "        super().__init__()\n",
    "        self.normalize = nn.BatchNorm2d(num_features=1)\n",
    "        self.linear1 = nn.Linear(in_features,1280,bias=False)\n",
    "        self.output = nn.Linear(1280,out_features, bias=False)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.normalize(x)\n",
    "        x = x.view(-1,28*28)\n",
    "        sigma1 = torch.relu(self.linear1(x))\n",
    "#         sigma1 = self.normalize(sigma1)\n",
    "        sigma2 = F.log_softmax(self.output(sigma1),dim=1)\n",
    "        return sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T02:00:03.664370Z",
     "start_time": "2022-07-16T02:00:03.601135Z"
    }
   },
   "outputs": [],
   "source": [
    "def fit(net,bacthdata,lr=0.01, epochs=5, gamma = 0):\n",
    "    criterion = nn.NLLLoss()\n",
    "    opt = optim.SGD(net.parameters(),lr=lr,momentum = gamma)\n",
    "    correct = 0 #循环开始之前，预测正确的值为0\n",
    "    samples = 0 #循环开始之前，模型一个样本都没有见过\n",
    "    for epoch in range(epochs): #全数据被训练几次\n",
    "        for batch_idx,(x,y) in enumerate(batchdata):\n",
    "            y = y.view(x.shape[0]) #降维\n",
    "            sigma = net.forward(x) #正向传播\n",
    "            loss = criterion(sigma,y)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            #求解准确率，全部判断正确的样本数量/已经看过的总样本量\n",
    "            yhat = torch.max(sigma, 1)[1] #torch.max函数结果中的索引为1的部分\n",
    "            correct += torch.sum(yhat == y)\n",
    "            samples += x.shape[0]\n",
    "            #每训练一个batch的数据，模型见过的数据就会增加x.shape[0]\n",
    "            \n",
    "            if (batch_idx + 1) % 125 == 0 or batch_idx == len(batchdata)-1: #每N个batch我就打印一次\n",
    "                print(\"Epoch{}:[{}/{}({:.0f}%)],Loss:{:.6f},Accuracy:{:.3f}\".format(\n",
    "                    epoch+1\n",
    "                    ,samples\n",
    "                    ,epochs*len(batchdata.dataset)\n",
    "                    ,100*samples/(epochs*len(batchdata.dataset))\n",
    "                    ,loss.data.item()\n",
    "                    ,float(100*correct/samples)\n",
    "                     ))\n",
    "            #分子代表：已经查看过的数据有多少\n",
    "            #分母代表：在现有的epochs设置，模型一共需要查看多少数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-16T02:00:03.999798Z",
     "start_time": "2022-07-16T02:00:03.900513Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "expected 4D input (got 2D input)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_12370/3141318890.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmanual_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m420\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatchdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_12370/978896259.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(net, bacthdata, lr, epochs, gamma)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#降维\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msigma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#正向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_12370/2176257417.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0msigma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0msigma1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0msigma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msigma1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msigma2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts_env/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts_env/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0;31m# exponential_average_factor is set to self.momentum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ts_env/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36m_check_input_dim\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_input_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"expected 4D input (got {}D input)\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: expected 4D input (got 2D input)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(420)\n",
    "net = Model(in_features=input_, out_features=output_)\n",
    "fit(net,batchdata,lr=lr,epochs=epochs,gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ts_env",
   "language": "python",
   "name": "ts_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
